* java并发
  * 什么是进程和线程
    
    进程：程序的开始到关闭的过程就是一个进程，所以我们可以用进程来造句：这个进程开了很久（这个程序还没关），任务管理器的这个进程在哪（找它的PID，程序编号/进程编号）

    线程：一个进程有main主线程和其他线程构成，线程共享进程的堆和方法区，却又有独自的程序计数器（指向指定地址），虚拟机栈（java方法的局部变量）和本地方法栈（本地方法的局部变量，本地方法的意思却是调用C语言，可能本地指在不懂地调用非java语言吧）。
   * 线程的转换
   
     启动》可执行》因为其他线程用了锁而阻塞/睡眠等待/挂起等待（被罚站一样，要么惩罚执行完，要么等老师通知）》terminate完毕
     
  * 进程和线程的关系，区别和优缺点
  
    一个进程有多个线程，线程是进程的更小执行单元。区别是原来线程会相互影响，因为共用了堆的对象和方法区的一些变量；进程是独立，进程会可能会共享同一个外部资源，但不会分享自己的内部资源，所以不会互相影响。因此优缺点很明显：进程的资源安全问题更好，适合管理隔离一些资源；而线程有切换速度开，开销小的特点。
    
  * 并发和并行
    
    并行是同一时间点做任务，与CPU内核数一样；并发是同一时间段多任务，与线程数一样。
    所以项目开发追求高并发而不是高并行，就是因为并行处理任务数量被物理条件内核限制住了，处理不了海量请求。
    
  * 什么是上下文切换
    
    线程间按照时间片轮转的切换就是上下文切换，linux系统切换开销小，怪不得在虚拟机上搭建集群。
    
   * 什么是死锁，如何避免
   
     通俗讲，死锁就是多个线程共享资源，对资源上锁，又不会因为后来的请求而释放，忙则等待，所以一旦出现进程占用了彼此需要的不同资源就会无限期等对方释放，而对方需要他的资源释放才能完成的矛盾。
     避免就是破坏死锁的条件，互斥是不可能的，可以的是一次性申请资源或在申请不到资源就把自己的才释放或以同样的顺序请求资源

   * 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？
   
     因为线程start后不一定就立马run，得等分配到时间片、资源；如果直接调用run，就不是线程了，和普通函数一样了。
     
   * 说说 sleep() 方法和 wait() 方法区别和共同点?
   
      sleep是睡眠等待,wait是挂起等待；sleep在一定时间后会自动唤醒，wait需要被notify或等其他线程执行完；wait适合进程通信，会释放锁，让资源流动，sleep只是简单地暂停。

* java并发进阶
  * synchronized的了解，使用，底层，JDK1.6 之后的底层优化，谈谈 synchronized和ReentrantLock 的区别

     synchronized关键字可以实现多线程的资源加锁，完成同步。

    它的使用分别是修饰类，方法和代码块，相当于给他们上锁，一旦对象实例化，必须拿到相应的锁才能执行方法。锁还分静态和非静态，它们可以是同名，也可以同时使用。双重校验锁实现对象单例（线程安全）

    底层是对于代码块来说，是用监视器的monitorenter开始上锁，moniterexit结束释放；对于类来说使用ACC_SYNCHRONIZED标识符让JVM去识别。

    1.6的优化包括：由于传统的锁是重量级锁，锁的线程是映射到很远的操作系统线程上的，申请互斥量就要跑很远，还需要从用户态转变内核态，这是很耗费时间的。所以当不用申请互斥量，也就是竞争不激烈时，1.无竞争且只有一个线程可以采用偏向锁（大致作用就是第一个申请的线程使用一次CAS，记录到MarkWord里，以后申请就直接给它锁，不用多次CAS/申请互斥量）2.偏向锁失败？升级为轻量级锁，多次CAS解决申请锁问题3.自旋锁，就是不挂起休息（因为挂起需要跑到操作系统做状态转换），循环地问有没有锁可以用了。

    ReenTrantLock和Synchronized 都是"可重入锁"（同一线程可以多次调用同一锁，像是用了add方法，锁计数器+1；用了同一的类mul方法，计数器再+1；不可重入锁add时候不能mul了），前者是API，后者是JVM；前者的锁对象一个可以有多个“Condition”实例，线程可以放在实例上，这让ReentrantLock可以选择性地加锁，而且notifyAll（）的时候只会唤醒同一个实例上的线程而不是所有实例上的线程。

   * JMM是什么， 说说 synchronized 关键字和 volatile 关键字的区别

     JMM是JAVA内存模型，它是JAVA内存的“访问规范”，也就是怎么访问内存可以更安全，更高效。

     它的访问规范是这样的：主内存存放所有变量，线程有各自的独立工作内存，里面存放的主内存的拷贝变量！问题在于多线程访问，可能一个线程改变了某一变量，但另一线程还在用没更新的拷贝副本变量操作。所以要改变之后立马同步到主内存，用这个变量就去主内存更新变量值，所以volatile就是说明这个变量是同步的，是需要这么做的。

     volatile只能修饰变量，因为使用更新的原理，所以不会阻塞问题；同时它主要是实现变量的可见性，而不能够实现原子性，synchronized则注重资源的同步性。
    
    * 线程的使用
    
      实现Runnable重写run方法或实现Callable重写call方法（可以有返回值），但他们都是“任务”,不算线程，反倒像线程里的run，所以终归是需要Thread.start(参数)，参数是Runnbale对象或者Callable用FutureTask封装的对象。
    
     再或者继承Thread，Java是单继承，多接口，所以上面两种方法虽然像是run，Thread自己也可以，但是价值就在这里。
    
    * ThreadLocal是什么
    
      ThreadLocal就是申明，我想改这个变量但不想同步到主内存里，像是日期格式，这样每个线程可以有自己设计的格式。底层原理是ThreadLocal其实是ThreadLocalMap的封装类，这个map,key是本地线程对象（弱引用），value是你赋的值（强引用，得用方法变成弱引用才能GC）
    
    * 为什么要用线程池
     
      将线程集中在线程池可以统一管理、监控，也可以限制线程数，而且它更像Redis的缓存，可以重复利用，所以降低线程重复创建和销毁的能耗，与此同时提高已有线程调用的响应速度。
    
    * JUC 包中的原子类是哪4类?好处是什么?
      
      JUC就是java.util.concurrent，并发包；其实它的原子类的作用是用它定义的原子类去包装你的数据，然后你用它封装的方法操作（以原子的方式去更新数据），所以好处就是你不用去给方法声明synchronized，就可以实现资源共享（感觉像volatile封装成各个原子类名，还加了方法）；
      既然是以原子的方式去更新数据，就有4种数据类型：基本数据类型（AtomicInteger/Long/Boolean）,数组类型(AtomicInteger/Long/ReferenceArray),引用类型（AtomicReference/StampedReference/MarkableRefernce）,对象的属性修改类型（AtomicLongField/IntegerFieldUpdater,AtomicStampedReference）
      
    * 能不能给我简单介绍一下 AtomicInteger 类的原理
    
      用本地方法unsafe的objectFieldOffset获得旧值的地址，采用cas去置换，保存到volatile变量去可见。
    
    * AQS是什么，AQS 原理是什么，AQS定义两种资源共享方式，AQS底层使用了模板方法模式
    
      AQS是锁和同步器的框架，很多锁（ReentrantLock,Semophoe等）都是在这个框架的基础上搭建的，也就是重写AQS的方法。
      
      原理有点搞笑，以为是怎怎么么同步，到头来只是管理线程阻塞如何排队和唤醒（但这确实就是锁的雏形啊），还以为是怀着特警的梦想去当了交警。
      
      用了双向的虚拟队列去访问资源，去节点建立联系。
      
      资源分为独占（单线程锁ReentrantLock）和分享（多线程锁CountDownLatch）
      
      模板方法模式就是继承AbstractQueuedSynchronizer，去重写它的方法。
      
      值得一提的模板方法就那几个：判断是否独占资源（isHeldExclusively），抢占/释放资源(tryAcquire/Release,共享方式的：tryAcquireShared,tryReleaseShared.
      
    
    * interrupt()和interrupted() 中断
      
       一个线程Thread.interrupt()意味着它被中断，如果中断的时候它是阻塞、等待的，中断会把它提前结束进程（该线程后面的代码就不执行了）；如果它是在running情况下被中断，可以用interrupted（）来判断是否中断（所以你要在中断时候执行后面的代码，就用while(!interrupted()),run的实际逻辑在while里）
      
    * Executor的中断，指定中断
    
      发现他挺多用Executor.newCacheThreadPool()->.execute(()->{})方法来启动线程；.shutDownNow()相当于interrupt（）
      
      如果只想中断某一个线程就.submit(()->{}),应该是其他的照样用.execute()，submit返回Future<?>变量->.cancel(true)中断
     
    * synchronized的具体用法 ReentrantLock的具体用法 比较
    
      synchronized除了用在方法前，其他的如代码块、类都得在（）里指明如synchronize(this),synchronize(xxx.class);
      
      值得一提的是同步的范围，除了类和静态方法可以被不同对象共享外，其他只能在同一个对象里共享。
      
      ReentrantLock通过新建对象，在向上锁的地方.lock/.unlock 来使用
      
      他两的区别是：同步是共享资源上锁，可重入锁是独占资源上锁；值得一提的是同步是JVM实现，可重入锁是JDK实现，因此同步有更广的可用性，不用考虑JDK版本问题；可重入锁可以是公平锁，绑定多条件
    
    * join()
    
      有先后顺序时用join（），让一个线程挂起等另一个线程好在执行，这时join的线程并非申请不到资源，所以不算忙等待，只是等才能准确。
     
    *  Object 的方法 await()方法 
    
      wait方法属于Object方法，这让他直接可以使用wait()；sleep是Thread的方法，所以还得前缀Thread.sleep();
     
      await就是比wait多了可指定条件唤醒，signal/signalAll；await是Condition上的方法，Condition有锁来创建
    
    * CountDownLatch的用法 CyclicBarrier的用法 Semaphore的用法
    
      都是创建对象的时候指定限制数量，前两个都是等到数量到了自动被唤醒countDownLatch.await();countDownLatch.countDown()/cyclicBarrier.await()它默默在计数，而不是倒计时到0；
      Semaphore则是.acquire()/.release()，申请-1，完成+1,资源执行。
    
    * 构造函数有多个
      
      但是创建对象，初始化只有1个。
    
    
     * 并发容器有哪些，它们的实现或好处是什么
     
        并发容器有点像原子类一样，不过是用并发的方式去封装普通类，所以有：ConcurrentHashMap、CopyOnWriteArrayList、（线程安全的队列分为哪两种）ConcurrentLinkedQueue、BlockingQueue 
      
       ConcurrentHashMap就是把HashMap封装成多线程安全的；CopyOnWrite就是拷贝副本之后改副本，~ArrayList好处是读取不用加锁（因为整个数组替换）；（阻塞队列要加锁，非阻塞队列CAS）；BlockingQueue阻塞队列，适合消费者-生产者模式，它有数组，链表，队列三种，前两种是有界队列。
     
     * FutureTask BlockingQueue 
     
       FutureTask，Future可以接受返回值，Task可以做任务，所以它是实现了Future接口和Runnable接口，它可以异步获取数据，异步就是你可以让他计算，期间你去做别的事，而且在Thread启动它的时候，最后直接用FutureTask.get()获得值不用Thread去获得。
       
       take/put,取和放，满/空会阻塞
      
     * ForkJoin 
     
       分支连接，和MapReduce有点像，缩小任务并行计算，所以它会像递归一样，last-first看规模够不够小，不够折半，左右.fork()启动，
       最后把左右结果.join相加（这样就是递归到底层，线程必须从底向上返回）
       
       注意用ForkJoinPool去submit,它比较有用，用了工作窃取算法，也就是别的进程可以帮你做你最老的任务。
       
     * 主内存与工作内存的意义 内存间交互操作与原子类和synchronized的互动、先行发生原则、线程安全实现方式
     
        意义是为了给缓存擦屁股，因为寄存器处理速度远大于内存，所以用缓存来最大限度发挥寄存器性能，没有主内存这些概念，也就是没有JMM规范，会数据不一致。
        
        内存间交互操作：最好想象图，Thread->(assign)工作内存->(store)主内存（write）
                                 Thread(use)<-工作内存（load）<-(read)<- 主内存
                                 主内存的操作有lock/unlock，这就是原子类和同步的底层
        
        先行发生原则感觉一堆废话，还好的就是join()
        
        线程安全的实现方式分为同步和不同步，同步影响最深的就是不可变（你不允许别人改，想怎么同步随便），最意外的是互斥同步就是悲观锁，悲观就是不管有没有竞争都要走一套流程（耗费资源的加锁、维护锁计数器，查看锁唤醒） synchronized和ReentrantLock；所以有了非阻塞同步，CAS、原子类这些。不同步在下面。
                        
     
     * 栈封闭、“一个请求对应一个服务器线程”、锁消除锁粗化
    
        方法的局部变量在工作内存；就是请求的逻辑都一样所以写在同个类，这样线程启动就是在同一个线程，为了不同客户不影响所以用了ThreadLocal（只展示set方法）；锁消除就是发现他其实永远不会逃逸到其他线程，所以访问它不用老是加锁；锁粗化就是一段代码10行每个操作都是加锁，这样太频繁了，所以在这10行外加锁就行，进来一次。
    
    
    * 乐观锁和悲观锁的使用场景，版本号机制
    
      乐观锁使用在读多写少的场景，悲观锁使用在写多、竞争激烈的场景。版本号机制AtomicStampedReference估计就是SVN的原理了。
    
* 分布式
 
  * 分布式锁的使用场景，数据库的唯一索引的作用，redis的setnx指令和expire指令、redLock算法为什么要获得大多数实例的锁一个不行？zookeeper实现分布式锁
  
    资源可能被不同节点，不同主机共享，这个时候
    
    唯一索引，申请到锁就插入数据库，别人就不能用了，唯一是为了让别人不能再插入（问题自己不可重入了）
    
    setnx是为了申请不到锁放回false而不是报错，expire是防止锁一直占着。（这些都是在解决数据库的分布式锁产生的问题）
    
    多个Redis实例集群是为了实现高可用，突然明白之所以要大多数是因为一来是看看有没有已经上锁的了，二来是在没有的情况看谁先上锁，否则如果只拿到1个就上锁并同步其他的实例，很可能冲突 -》*《-
    
    zookeeper分布锁就没那么多问题 ，它是树形节点，3种节点（临时节点防止一直占着），监视器监控，客户端通过到/lock/xx目录下看自己的节点编号是不是最小，是的话说明没人用，采用羊群效应（每个节点只通知后面的节点可用了）。
  
  * 分布式事务要做到什么，2PC，存在的问题（想象图）
  
     做到一个修改，所有集群都ACID。
     
     分布式事务提交还分两个阶段啊，用的是协调者（Coordinator，只有一个崩了就没了）,询问参与者（线程事务）执行完没（这个过程阻塞），协调者让执行完的提交（这样存在没执行完的，这样数据不一致；而且一个错就算全部错，都不给降级机会）
  
  * 本地消息表的作用 
  
     就是一个节点执行事务，登记操作到这个表，这个表把信息给消息队列（失败，重试到对，容错到数据一致？？）传递给另一个节点，节点跟着操作建立。
  
  * 可用性 分区容忍性
  
    可用性就是高可用那意思；节点分区，允许部分区坏了其他照常CA，所以P基本上dubbo和springcloud都有。
  
  * BASE Paxos Raft
  
    分布式事务除了满足ACID，也可以只满足BASE：基本可用，软状态（允许更新到另一节点延时），最终一致性（！=ACID的强一致性，它不是面向数据库，所以它可以高可用。）
    
    Paxos算法使用来“接受”多个“提议”然后“learn”只选出一个值的，就投票看用哪个提议，【n,v】序号要比我大我才看到你的v
    
    Raft算法是选出节点的leader的，follower如果没有leader的定时限制，就会躁动成cardinate，向别人求票，过半数就leader，然后定时给follower压制。多个候选人因为有随机竞选超时，所以下一次大概率就出了。

* 集群

  * 负载均衡算法是根据什么决定用那种（轮询、随机、最少连接数、加权轮询、加权最少连接数、“IP哈希”）
  
    服务器的性能，性能差不多就轮询（你一个我一个）/随机；有性能突出的就应该多接受请求，所以用了加权轮询（权是连接速度）；还有不少看性能的，找队伍最短的；
    
    IP哈希是计算地址哈希值决定负载均衡到哪个服务，好处是每次访问同一个服务器，坏处是对于同一个客户端不均衡，那个服务器崩了就没地方去了。
  
  * 转发实现问的是如何把请求发到某个地方（那里才进行负载均衡算法，确实毕竟客户端也没有这算法，我服务器才有）
  
    最后觉得源服务器，负载均衡服务器到底是什么他没说清楚，有了负载算法为什么还得一定要经过负载均衡服务器，源地址和目的地址调转不就得？
  
    所以总得来说，有源服务器（客户端），反向代理服务器，负载均衡服务器；感觉负载均衡算法在哪，哪就有目的IP，可却不一定是负载均衡服务器，因为请求的响应会经过负载均衡服务器，DNS/你自己/反向代理不必须(正是因为调转地址就得，所以不用非得经过DNS，和到源服务器就停不用再接着去到的反向代理服务器。可是源服务器是自己，请求竟然先反向代理再自己，好像也行.. 
 
     请求是要通过转发才能找到正确的服务器的。现在看来转发最需要的是目的IP，负载均衡算法该在哪里用，有的在DNS解析过程用，有的在网络层、链路层（他们算源服务器出发吧，链路层可以直接路由，避开负载均衡服务器),有的找反向代理服务器（应该都有，功能主要是缓存，日志记录，找它负载说只是为功能集成在一起，好看？？）
  
  * 集群下的 Session 管理问的这么多服务器同一个用户session存哪里
  
    Sticky Session会话粘滞就是IP哈希算法，让同一个用户存在同一个服务器，不高可用
    
    服务器间同步session,太耗带宽
    
    专门一个session服务器
  
 * Redis
  
    * Redis其实是非关系型数据库而且数据存在内存中所以快，它的key只支持String,value支持哪五种，他们的操作如何增删查改有什么和其他类型不一样的
      （太简单了，不给答案）
    * 跳跃表是盖楼连线接查找的值
    * 为什么学redis，它可以缓存数据库数据，但它的使用场景还有存储会话信息，给DNS解析做缓存。（Set可以交集做共同好友功能，ZSet可以做排行榜功能）
    * redis淘汰策略是在内存不够时移除掉一些没用的给别人腾空间，策略分为从设置了过期时间的volatile-xx或allkeys里面用随机算法或是lru（最近最少使用）或是ttl快过期或是不淘汰。他建议Redis的内存最大容量设置为热点数据的内存大小，然后用lru去淘汰
    * redis持久化有两种RDB和AOF（append only file，有个AOF文件，把数据追加到它后面，放缓存区，看是什么时候保存磁盘）
    * redis的过期原理是到时间后，定期删除+惰性删除（定期删除可能由于数量大，而他是隔一段时间抓一批，比较不可能一次性抓完大数据，所以会有残留，残留在再次调用启动惰性删除）
    * redis 事务支持多个命令一起发，multi指令，流水线
* 消息队列

  * 消息模型有哪两个？和观察者模式相比有什么不同
  * 使用场景，就是问好处价值市场
  * 发送端和接收端的可靠性体现，实现方式
* RPC
  * 概念，主要技术，实现过程，方案，“使得开发分布式程像本地程序一样简单”？
  * RPC四种框架，选择的依据：代码入侵，需要长连接，需要跨越网段和防火墙
  * Dubbo 分布式服务不等于微服务 架构图中服务容器是负责启动，加载，运行提供者的 两端都有缓存 服务端无状态 我的淘淘商城用的就是dubbo直连（消费者直接指定服务者，绕过了注册中心的查询）
  * 消息队列 削峰和流控  常见消息队列在吞吐量、可用性、时效性、功能支持上的比较
* RabbitMQ在提供者和消息队列中间还有交换器（路由选择哪个队列） 把broker中断器当做服务器、服务节点好奇怪啊
* RabbitMQ交换器4种类型
  
